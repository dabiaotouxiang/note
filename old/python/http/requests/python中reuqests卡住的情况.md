前一阵帮别人写了个爬虫，获取商品列表的爬虫，结果服务总是无缘无故的卡住，一开始以为是nohup的原因。今天调试的时候突然发现是requests卡住了。上网查了一下，设置了timeout，后面没有再出现卡住的问题。

<!-- more -->

requests的超时分为两种，一种是链接超时，一种是读取超时。

requests的请求过程可以分为下面几步:
1. requests客户端与服务端建立链接。
2. 服务端向requests发送返回数据。

链接超时指的是客户端在设置的时间内无法与服务端建立链接（没有配置的话有默认的数值）

读取超时指的是服务端没有在设置的时间内开始向服务端返回数据（没有配置的话，没有默认值）

我的服务就没有配置超时时间，我一直以为都有默认的超时时间，就没有配置，所以服务就卡住了。

配置方式，整体配置:
```
# 两个整体不可超过15秒
requests.get('xxxx', timeout=15)
# 分别配置，链接超时不可超过5秒，读取超时不可超过10秒
requests.get('xxxx', timeout=(5, 10))
```


### 原文[【Python 库】requests 详解超时和重试](https://www.cnblogs.com/gl1573/p/10129382.html)